# -*- coding: utf-8 -*-
"""KnowledgeGraph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16FLyT_QQtDcieYhjUps6fjXaDizatNAN
"""
import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import ampligraph as ampli
from ampligraph.latent_features import TransE
from ampligraph.evaluation import train_test_split_no_unseen

# Set the backend (use 'tf' for TensorFlow or 'torch' for PyTorch)
ampli.init()

def create_knowledge_graph(df, source_col, target_col, relation_col):
    G = nx.Graph()

    for _, row in df.iterrows():
        G.add_node(row[source_col], label=row[source_col])
        G.add_node(row[target_col], label=row[target_col])
        G.add_edge(row[source_col], row[target_col], relation=row[relation_col])

    return G

def train_embeddings(df, model, epochs=100):
    X = df[['Source', 'Target', 'Relation']].values
    X_train, X_test = train_test_split_no_unseen(X, test_size=0.1)
    
    model.fit(X_train, epochs=epochs)

    return model

def get_node_embeddings(model, nodes):
    embeddings = model.get_embeddings(nodes, embedding_type='entity')
    return embeddings

def draw_knowledge_graph(G, node_size, edge_width, node_embeddings=None):
    pos = nx.circular_layout(G)  # Using a circular layout for simplicity
    edge_labels = nx.get_edge_attributes(G, 'relation')

    fig, ax = plt.subplots()
    nx.draw(G, pos, with_labels=True, node_size=node_size, node_color='skyblue', font_size=8, font_color='black', font_weight='bold', width=edge_width)
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)

    if node_embeddings is not None:
        for node, (x, y) in pos.items():
            emb = node_embeddings.get(node)
            if emb is not None:
                ax.text(x, y + 0.05, f'{emb[0]:.2f}, {emb[1]:.2f}', fontsize=8, ha='center')

    st.pyplot(fig)

def main():
    st.title("Dynamic Knowledge Graph App")

    uploaded_file = st.file_uploader("Upload CSV file", type=["csv"])

    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)

        # Get column names dynamically
        source_col, target_col, relation_col = st.columns(3)
        source_col_name = source_col.text_input("Enter Source Column Name", value=df.columns[0])
        target_col_name = target_col.text_input("Enter Target Column Name", value=df.columns[1])
        relation_col_name = relation_col.text_input("Enter Relation Column Name", value=df.columns[2])

        knowledge_graph = create_knowledge_graph(df, source_col_name, target_col_name, relation_col_name)

        st.subheader("Data Preview:")
        st.write(df.head())

        st.subheader("Knowledge Graph Visualization:")

        # Train embeddings using AmpliGraph
        model = TransE(batches_count=10, epochs=100, k=20, eta=2, loss='pairwise', verbose=True)
        trained_model = train_embeddings(df, model)

        # Sliders for customization
        node_size = st.slider("Node Size", min_value=1, max_value=100, value=20)
        edge_width = st.slider("Edge Width", min_value=0.1, max_value=5.0, value=1.0, step=0.1)

        # Get embeddings for nodes
        nodes = df['Source'].append(df['Target']).unique()
        node_embeddings = get_node_embeddings(trained_model, nodes)

        draw_knowledge_graph(knowledge_graph, node_size, edge_width, node_embeddings)

if __name__ == "__main__":
    main()
